{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bef85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96899ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLASH2_result_folder=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2685b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in p-values, afetr_correction.scores.csv file\n",
    "fname=SPLASH2_result_folder+'/result.after_correction.scores.csv'\n",
    "df = pd.read_csv(fname,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### can change thresholds\n",
    "\n",
    "effectSizeThresh = np.quantile((df[\n",
    "    (df.pval_opt_corrected<.05) &\n",
    "                (df.M>1000)]).effect_size_bin,[.9])[0]\n",
    "print('effect size thresh', effectSizeThresh)\n",
    "\n",
    "df_filtered = (df[(df.pval_opt_corrected<.05) &\n",
    "                (df.effect_size_bin>effectSizeThresh) &\n",
    "                (df.M>1000)])\n",
    "\n",
    "reducedAnchLst = df_filtered.anchor.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2edb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3054ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ffcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load in c vectors, keeping only the ones corresponding to relevant anchors\n",
    "### this is currently fast enough, but for larger datasets may need faster methods here, utilizing SATC tools\n",
    "dfArr = []\n",
    "\n",
    "##### path to intermediary_files output folder\n",
    "fldrName= SPLASH2_result_folder+'/intermediary_files'\n",
    "\n",
    "for fname in tqdm(glob.glob(fldrName+'result.bin*.cjs')):\n",
    "    dfArr.append(\n",
    "        pd.concat(chunk[chunk.anchor.isin(reducedAnchLst)] for chunk in pd.read_csv(fname,sep='\\t',chunksize=1E7))\n",
    "    )\n",
    "    \n",
    "## concatenate\n",
    "dfcj = pd.concat(dfArr)\n",
    "\n",
    "### pivot to matrix form\n",
    "pivotedDf = dfcj.pivot(index=['anchor'], columns='sample', values='Cj').fillna(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
